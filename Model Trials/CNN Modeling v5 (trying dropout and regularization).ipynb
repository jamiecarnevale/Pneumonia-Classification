{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c0c7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import os, shutil\n",
    "import time\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import cv2\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7dd375",
   "metadata": {},
   "source": [
    "# Now lets try and to make the results better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70225cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data generator\n",
    "datagen2 = ImageDataGenerator(\n",
    "    rescale=1./255, # normalize pixel values\n",
    "    rotation_range=20, # randomly rotate images in the range\n",
    "    zoom_range=0.2, # randomly zoom image \n",
    "    width_shift_range=0.2, # randomly shift images horizontally\n",
    "    height_shift_range=0.2, # randomly shift images vertically \n",
    "    horizontal_flip=True) # randomly flip images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57a15b4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4098 images belonging to 2 classes.\n",
      "Found 879 images belonging to 2 classes.\n",
      "Found 879 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Use flow_from_directory to read images from folders\n",
    "train_generator2 = datagen2.flow_from_directory(\n",
    "        'CellData/chest_xray/train', # point to the parent directory\n",
    "        target_size=(299, 299), # resize images to 299x299\n",
    "        batch_size=32,\n",
    "        class_mode='binary') # binary for two classes\n",
    "\n",
    "# Similarly create validation and test generators\n",
    "val_generator2 = datagen2.flow_from_directory(\n",
    "        'CellData/chest_xray/val',\n",
    "        target_size=(299, 299),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_generator2 = datagen2.flow_from_directory(\n",
    "        'CellData/chest_xray/test',\n",
    "        target_size=(299, 299),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3019617e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = models.Sequential()\n",
    "model2.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(299, 299, 3)))\n",
    "model2.add(layers.BatchNormalization())\n",
    "model2.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(layers.Dropout(0.25))\n",
    "\n",
    "model2.add(layers.Conv2D(64, (4, 4), padding='same', activation='relu'))\n",
    "model2.add(layers.BatchNormalization())\n",
    "model2.add(layers.Dropout(0.25))\n",
    "\n",
    "model2.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "model2.add(layers.BatchNormalization())\n",
    "model2.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(layers.Dropout(0.25))\n",
    "\n",
    "model2.add(layers.Flatten())\n",
    "model2.add(layers.Dense(128, activation='relu'))\n",
    "model2.add(layers.BatchNormalization())\n",
    "model2.add(layers.Dropout(0.5))\n",
    "model2.add(layers.Dense(128, activation='relu'))\n",
    "model2.add(layers.BatchNormalization())\n",
    "model2.add(layers.Dropout(0.5))\n",
    "model2.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model2.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c2c7fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 2991, 0: 1107})\n",
      "2991.0\n",
      "{0: 2.7018970189701896, 1: 1.0}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "# Get class distribution\n",
    "counter = Counter(train_generator2.classes)                          \n",
    "max_val = float(max(counter.values()))       \n",
    "class_weights = {class_id : max_val/num_images for class_id, num_images in counter.items()}                     \n",
    "\n",
    "print(counter)\n",
    "print(max_val)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f92810f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-12 20:09:22.040957: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - ETA: 0s - loss: 0.9626 - acc: 0.6928"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-12 20:11:14.821812: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 127s 967ms/step - loss: 0.9626 - acc: 0.6928 - val_loss: 1.2738 - val_acc: 0.7292\n",
      "Epoch 2/30\n",
      "129/129 [==============================] - 111s 855ms/step - loss: 0.6143 - acc: 0.8028 - val_loss: 2.0724 - val_acc: 0.7292\n",
      "Epoch 3/30\n",
      "129/129 [==============================] - 118s 907ms/step - loss: 0.4821 - acc: 0.8582 - val_loss: 2.3810 - val_acc: 0.7292\n",
      "Epoch 4/30\n",
      "129/129 [==============================] - 118s 906ms/step - loss: 0.4309 - acc: 0.8770 - val_loss: 1.0241 - val_acc: 0.7315\n",
      "Epoch 5/30\n",
      "129/129 [==============================] - 119s 914ms/step - loss: 0.4245 - acc: 0.8821 - val_loss: 2.3099 - val_acc: 0.2981\n",
      "Epoch 6/30\n",
      "129/129 [==============================] - 125s 962ms/step - loss: 0.4082 - acc: 0.8804 - val_loss: 3.4900 - val_acc: 0.7292\n",
      "Epoch 7/30\n",
      "129/129 [==============================] - 115s 889ms/step - loss: 0.3951 - acc: 0.8856 - val_loss: 4.4734 - val_acc: 0.7292\n",
      "Epoch 8/30\n",
      "129/129 [==============================] - 108s 830ms/step - loss: 0.3945 - acc: 0.8853 - val_loss: 0.1957 - val_acc: 0.9226\n",
      "Epoch 9/30\n",
      "129/129 [==============================] - 113s 867ms/step - loss: 0.3771 - acc: 0.8931 - val_loss: 8.9903 - val_acc: 0.2730\n",
      "Epoch 10/30\n",
      "129/129 [==============================] - 113s 871ms/step - loss: 0.4009 - acc: 0.8882 - val_loss: 0.5797 - val_acc: 0.7395\n",
      "Epoch 11/30\n",
      "129/129 [==============================] - 113s 866ms/step - loss: 0.3601 - acc: 0.8982 - val_loss: 3.8855 - val_acc: 0.2867\n",
      "Epoch 12/30\n",
      "129/129 [==============================] - 110s 847ms/step - loss: 0.3448 - acc: 0.9002 - val_loss: 1.4338 - val_acc: 0.5176\n",
      "Epoch 13/30\n",
      "129/129 [==============================] - 108s 830ms/step - loss: 0.3458 - acc: 0.9039 - val_loss: 0.4203 - val_acc: 0.7918\n",
      "Epoch 14/30\n",
      "129/129 [==============================] - 115s 886ms/step - loss: 0.3766 - acc: 0.8960 - val_loss: 2.4388 - val_acc: 0.7292\n",
      "Epoch 15/30\n",
      "129/129 [==============================] - 108s 832ms/step - loss: 0.3561 - acc: 0.8973 - val_loss: 2.2639 - val_acc: 0.7292\n",
      "Epoch 16/30\n",
      "129/129 [==============================] - 121s 934ms/step - loss: 0.3161 - acc: 0.9146 - val_loss: 0.4959 - val_acc: 0.7474\n",
      "Epoch 17/30\n",
      "129/129 [==============================] - 114s 877ms/step - loss: 0.3678 - acc: 0.9021 - val_loss: 1.5443 - val_acc: 0.4994\n",
      "Epoch 18/30\n",
      "129/129 [==============================] - 115s 876ms/step - loss: 0.3517 - acc: 0.8943 - val_loss: 1.6893 - val_acc: 0.7292\n",
      "Epoch 19/30\n",
      "129/129 [==============================] - 115s 888ms/step - loss: 0.3387 - acc: 0.9039 - val_loss: 2.3795 - val_acc: 0.7292\n",
      "Epoch 20/30\n",
      "129/129 [==============================] - 109s 839ms/step - loss: 0.3229 - acc: 0.9082 - val_loss: 2.0559 - val_acc: 0.7292\n",
      "Epoch 21/30\n",
      "129/129 [==============================] - 109s 826ms/step - loss: 0.3179 - acc: 0.9153 - val_loss: 0.9193 - val_acc: 0.7338\n",
      "Epoch 22/30\n",
      "129/129 [==============================] - 103s 787ms/step - loss: 0.3174 - acc: 0.9185 - val_loss: 7.4520 - val_acc: 0.2742\n",
      "Epoch 23/30\n",
      "129/129 [==============================] - 97s 741ms/step - loss: 0.3217 - acc: 0.9070 - val_loss: 0.1857 - val_acc: 0.9238\n",
      "Epoch 24/30\n",
      "129/129 [==============================] - 94s 720ms/step - loss: 0.3151 - acc: 0.9158 - val_loss: 0.6802 - val_acc: 0.7008\n",
      "Epoch 25/30\n",
      "129/129 [==============================] - 93s 716ms/step - loss: 0.3027 - acc: 0.9168 - val_loss: 1.4943 - val_acc: 0.7292\n",
      "Epoch 26/30\n",
      "129/129 [==============================] - 92s 709ms/step - loss: 0.3078 - acc: 0.9187 - val_loss: 0.1786 - val_acc: 0.9374\n",
      "Epoch 27/30\n",
      "129/129 [==============================] - 92s 708ms/step - loss: 0.3016 - acc: 0.9170 - val_loss: 0.5230 - val_acc: 0.7577\n",
      "Epoch 28/30\n",
      "129/129 [==============================] - 92s 713ms/step - loss: 0.2923 - acc: 0.9163 - val_loss: 0.7662 - val_acc: 0.5961\n",
      "Epoch 29/30\n",
      "129/129 [==============================] - 92s 705ms/step - loss: 0.2952 - acc: 0.9197 - val_loss: 2.6269 - val_acc: 0.7292\n",
      "Epoch 30/30\n",
      "129/129 [==============================] - 93s 715ms/step - loss: 0.2838 - acc: 0.9263 - val_loss: 0.2110 - val_acc: 0.9158\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "\n",
    "steps_per_epoch2 = np.ceil(train_generator2.samples / train_generator2.batch_size)\n",
    "validation_steps2 = np.ceil(val_generator2.samples / val_generator2.batch_size)\n",
    "\n",
    "history = model2.fit(\n",
    "    train_generator2,\n",
    "    steps_per_epoch=int(steps_per_epoch2),\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator2,\n",
    "    validation_steps=int(validation_steps2),\n",
    "    class_weight=class_weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c277cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57302259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 59s 447ms/step - loss: 0.2446 - acc: 0.8880\n",
      "28/28 [==============================] - 13s 445ms/step - loss: 0.2200 - acc: 0.9033\n",
      "Training set performance: [0.24463430047035217, 0.8879941701889038]\n",
      "Validation set performance: [0.21997641026973724, 0.9032992720603943]\n"
     ]
    }
   ],
   "source": [
    "results_train = model2.evaluate(train_generator2)\n",
    "results_test = model2.evaluate(val_generator2)\n",
    "print('Training set performance:', results_train)\n",
    "print('Validation set performance:', results_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453ca5db",
   "metadata": {},
   "source": [
    "## a good bit worse than the last few models\n",
    "- regularization was not necessary as model was not overfit in the first place\n",
    "- did not help with score\n",
    "- likely will not include regularization in future models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3ab879",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tooters",
   "language": "python",
   "name": "tooters"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
