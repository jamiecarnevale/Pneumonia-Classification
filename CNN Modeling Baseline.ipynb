{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93c0c7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import os, shutil\n",
    "import time\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import cv2\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7dd375",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70225cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data generator\n",
    "# data augmentation\n",
    "datagen2 = ImageDataGenerator(\n",
    "    rescale=1./255, # normalize pixel values\n",
    "    rotation_range=20, # randomly rotate images in the range\n",
    "    zoom_range=0.2, # randomly zoom image \n",
    "    width_shift_range=0.2, # randomly shift images horizontally\n",
    "    height_shift_range=0.2, # randomly shift images vertically \n",
    "    horizontal_flip=True) # randomly flip images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57a15b4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4098 images belonging to 2 classes.\n",
      "Found 879 images belonging to 2 classes.\n",
      "Found 879 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Use flow_from_directory to read images from folders\n",
    "train_generator2 = datagen2.flow_from_directory(\n",
    "        'CellData/chest_xray/train', # point to the parent directory\n",
    "        target_size=(299, 299), # resize images to 299x299\n",
    "        batch_size=32,\n",
    "        class_mode='binary') # binary for two classes\n",
    "\n",
    "# similarly create validation and test generators\n",
    "val_generator2 = datagen2.flow_from_directory(\n",
    "        'CellData/chest_xray/val',\n",
    "        target_size=(299, 299),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_generator2 = datagen2.flow_from_directory(\n",
    "        'CellData/chest_xray/test',\n",
    "        target_size=(299, 299),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3019617e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-12 16:08:50.191708: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-07-12 16:08:50.191926: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "#this is the model with dense and conv layers\n",
    "\n",
    "model2 = models.Sequential()\n",
    "model2.add(layers.Conv2D(32, (5, 5), activation='relu',\n",
    "                        input_shape=(299 , 299,  3)))\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model2.add(layers.Conv2D(32, (4, 4), activation='relu'))\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model2.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model2.add(layers.Flatten())\n",
    "model2.add(layers.Dense(64, activation='relu'))\n",
    "model2.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44596ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 2991, 0: 1107})\n",
      "2991.0\n",
      "{0: 2.7018970189701896, 1: 1.0}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# this code creates class weights to address the data being imbalanced\n",
    "# counter counts the pneumonia vs normal images (1 being pneumonia)\n",
    "# the next line creates a dictionary assigning a weight to the NORMAL class (which is 0) \n",
    "# this weight for the NORMAL class is the number of PNEUMONIA images divided by the number of NORMAL images\n",
    "\n",
    "counter = Counter(train_generator2.classes)                          \n",
    "max_val = float(max(counter.values()))       \n",
    "class_weights = {class_id : max_val/num_images for class_id, num_images in counter.items()}                     \n",
    "\n",
    "print(counter)\n",
    "print(max_val)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f92810f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-12 16:09:10.718813: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-07-12 16:09:10.895561: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - ETA: 0s - loss: 0.7777 - acc: 0.7028"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-12 16:10:09.113021: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 71s 544ms/step - loss: 0.7777 - acc: 0.7028 - val_loss: 0.3614 - val_acc: 0.8737\n",
      "Epoch 2/30\n",
      "129/129 [==============================] - 71s 549ms/step - loss: 0.5451 - acc: 0.8404 - val_loss: 0.4468 - val_acc: 0.8589\n",
      "Epoch 3/30\n",
      "129/129 [==============================] - 70s 542ms/step - loss: 0.5111 - acc: 0.8594 - val_loss: 0.2683 - val_acc: 0.8817\n",
      "Epoch 4/30\n",
      "129/129 [==============================] - 72s 556ms/step - loss: 0.4869 - acc: 0.8638 - val_loss: 0.2568 - val_acc: 0.8896\n",
      "Epoch 5/30\n",
      "129/129 [==============================] - 71s 547ms/step - loss: 0.4617 - acc: 0.8626 - val_loss: 0.2662 - val_acc: 0.8931\n",
      "Epoch 6/30\n",
      "129/129 [==============================] - 69s 536ms/step - loss: 0.4380 - acc: 0.8777 - val_loss: 0.2292 - val_acc: 0.9067\n",
      "Epoch 7/30\n",
      "129/129 [==============================] - 68s 529ms/step - loss: 0.4458 - acc: 0.8804 - val_loss: 0.4594 - val_acc: 0.8316\n",
      "Epoch 8/30\n",
      "129/129 [==============================] - 68s 529ms/step - loss: 0.4544 - acc: 0.8675 - val_loss: 0.2509 - val_acc: 0.8931\n",
      "Epoch 9/30\n",
      "129/129 [==============================] - 68s 528ms/step - loss: 0.4471 - acc: 0.8724 - val_loss: 0.2687 - val_acc: 0.8942\n",
      "Epoch 10/30\n",
      "129/129 [==============================] - 69s 536ms/step - loss: 0.3920 - acc: 0.8887 - val_loss: 0.2631 - val_acc: 0.8965\n",
      "Epoch 11/30\n",
      "129/129 [==============================] - 69s 533ms/step - loss: 0.4169 - acc: 0.8795 - val_loss: 0.2448 - val_acc: 0.8976\n",
      "Epoch 12/30\n",
      "129/129 [==============================] - 68s 523ms/step - loss: 0.4070 - acc: 0.8829 - val_loss: 0.2641 - val_acc: 0.8976\n",
      "Epoch 13/30\n",
      "129/129 [==============================] - 69s 535ms/step - loss: 0.3996 - acc: 0.8831 - val_loss: 0.2335 - val_acc: 0.9101\n",
      "Epoch 14/30\n",
      "129/129 [==============================] - 70s 538ms/step - loss: 0.4072 - acc: 0.8858 - val_loss: 0.2673 - val_acc: 0.9022\n",
      "Epoch 15/30\n",
      "129/129 [==============================] - 70s 541ms/step - loss: 0.3948 - acc: 0.8880 - val_loss: 0.2181 - val_acc: 0.9113\n",
      "Epoch 16/30\n",
      "129/129 [==============================] - 69s 532ms/step - loss: 0.3944 - acc: 0.8846 - val_loss: 0.2298 - val_acc: 0.9181\n",
      "Epoch 17/30\n",
      "129/129 [==============================] - 68s 529ms/step - loss: 0.3544 - acc: 0.8973 - val_loss: 0.2400 - val_acc: 0.8965\n",
      "Epoch 18/30\n",
      "129/129 [==============================] - 69s 531ms/step - loss: 0.3555 - acc: 0.8960 - val_loss: 0.1855 - val_acc: 0.9204\n",
      "Epoch 19/30\n",
      "129/129 [==============================] - 69s 529ms/step - loss: 0.3365 - acc: 0.8992 - val_loss: 0.2141 - val_acc: 0.9158\n",
      "Epoch 20/30\n",
      "129/129 [==============================] - 68s 529ms/step - loss: 0.3481 - acc: 0.8980 - val_loss: 0.1958 - val_acc: 0.9249\n",
      "Epoch 21/30\n",
      "129/129 [==============================] - 68s 529ms/step - loss: 0.3469 - acc: 0.9068 - val_loss: 0.2338 - val_acc: 0.8953\n",
      "Epoch 22/30\n",
      "129/129 [==============================] - 68s 527ms/step - loss: 0.3505 - acc: 0.8995 - val_loss: 0.2079 - val_acc: 0.9147\n",
      "Epoch 23/30\n",
      "129/129 [==============================] - 68s 524ms/step - loss: 0.3131 - acc: 0.9056 - val_loss: 0.3349 - val_acc: 0.8783\n",
      "Epoch 24/30\n",
      "129/129 [==============================] - 68s 524ms/step - loss: 0.3246 - acc: 0.9061 - val_loss: 0.2056 - val_acc: 0.9249\n",
      "Epoch 25/30\n",
      "129/129 [==============================] - 68s 523ms/step - loss: 0.3068 - acc: 0.9102 - val_loss: 0.1914 - val_acc: 0.9181\n",
      "Epoch 26/30\n",
      "129/129 [==============================] - 68s 524ms/step - loss: 0.3380 - acc: 0.9029 - val_loss: 0.2373 - val_acc: 0.9101\n",
      "Epoch 27/30\n",
      "129/129 [==============================] - 69s 532ms/step - loss: 0.2990 - acc: 0.9168 - val_loss: 0.1987 - val_acc: 0.9261\n",
      "Epoch 28/30\n",
      "129/129 [==============================] - 68s 528ms/step - loss: 0.3259 - acc: 0.9029 - val_loss: 0.1776 - val_acc: 0.9261\n",
      "Epoch 29/30\n",
      "129/129 [==============================] - 68s 525ms/step - loss: 0.2922 - acc: 0.9119 - val_loss: 0.1794 - val_acc: 0.9192\n",
      "Epoch 30/30\n",
      "129/129 [==============================] - 68s 526ms/step - loss: 0.2758 - acc: 0.9207 - val_loss: 0.1767 - val_acc: 0.9317\n"
     ]
    }
   ],
   "source": [
    "# this is where the model is trained\n",
    "# the np.ceil part just makes sure that all the data (in batches) is being trained for each epoch\n",
    "# class weights is applied to deal with the imbalance in the dataset\n",
    "\n",
    "epochs = 30\n",
    "\n",
    "steps_per_epoch2 = np.ceil(train_generator2.samples / train_generator2.batch_size)\n",
    "validation_steps2 = np.ceil(val_generator2.samples / val_generator2.batch_size)\n",
    "\n",
    "history = model2.fit(\n",
    "    train_generator2,\n",
    "    steps_per_epoch=int(steps_per_epoch2),\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator2,\n",
    "    validation_steps=int(validation_steps2),\n",
    "    class_weight=class_weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf442fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57302259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 56s 428ms/step - loss: 0.1749 - acc: 0.9331\n",
      "28/28 [==============================] - 13s 446ms/step - loss: 0.1676 - acc: 0.9340\n",
      "Training set performance: [0.17489254474639893, 0.9331381320953369]\n",
      "Validation set performance: [0.16764609515666962, 0.9340159893035889]\n"
     ]
    }
   ],
   "source": [
    "results_train = model2.evaluate(train_generator2)\n",
    "results_test = model2.evaluate(val_generator2)\n",
    "print('Training set performance:', results_train)\n",
    "print('Validation set performance:', results_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "970664ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('modelv1weighted.h5')  # creates a HDF5 file for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4f8b75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tooters",
   "language": "python",
   "name": "tooters"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
